<!DOCTYPE html>
<html lang="ko">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Career | Tina Wiki</title>
  <meta name="description" content="Tina Jeong의 경력기술서 마스터 블록을 정리한 페이지입니다." />
  <link rel="canonical" href="https://www.tinawiki.com/career" />
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard-dynamic-subset.css" />
  <link rel="stylesheet" href="../styles.css" />
</head>

<body class="career-page">
  <header class="site-header">
    <div class="container">
      <div class="brand">
        <span class="brand-mark" aria-hidden="true">✎</span>
        <span class="brand-text">tina's wiki</span>
      </div>
      <nav class="site-nav" aria-label="주요 링크">
        <a href="/">블로그 홈</a>
        <a href="../posts.html">글</a>
        <a href="mailto:migujeong@gmail.com">연락</a>
      </nav>
    </div>
  </header>

  <main>
    <section class="career-summary" aria-labelledby="career-summary-title">
      <div class="container">
        <p class="callout">이 페이지는 블로그 밖에서 참고할 수 있도록 보관한 커리어 자료입니다. 사이트 메뉴에서는 링크되지 않습니다.</p>
        <h2 id="career-summary-title">요약</h2>
        <p>
          대용량 데이터를 다루는 배치 시스템과 마이데이터 플랫폼을 설계·구축·운영해왔습니다.
          레거시 배치를 현대화하고 테스트 자동화·데이터 자동 보정처리·운영 가시화처리를 통해 서비스 안정성과
          팀 생산성을 함께 끌어올렸습니다. 표준화된 개발·운영 문서와 대시보드를 통해
          신규 인력 온보딩과 장애 대응 속도를 체계적으로 개선했습니다.
        </p>
      </div>
    </section>

    <section class="career-master" aria-labelledby="career-master-title">
      <div class="container">
        <h2 id="career-master-title">경력기술서 마스터 블록</h2>

        <article class="career-block">
          <h3>정산 시스템 리빌딩 / 백엔드 개발자 @ 다날</h3>
          <p>
            27년간 운영된 SQL Server 기반 정산 시스템은 월 3천만 건을 하루 한 번 일괄 처리해 지연과 단일 장애 지점이 상시 존재했습니다.
            운영팀이 수동으로 재처리하고 새벽 배포를 반복하는 구조를 깨기 위해 배치 엔진을 Spring Batch 5와 멀티모듈(Core·Domain·Batch) 아키텍처로 재구성했습니다.
            수집·검증·집계·전송 단계를 실시간에 가까운 처리 주기로 분리하고, Chunk/Partitioner 전략을 통해 병렬 처리 파이프라인을 설계했습니다.
            결과적으로 처리 속도와 운영 복구력이 모두 향상되어 장애 대응이 자동화된 정산 환경을 만들었습니다.
          </p>
          <p class="career-stack"><strong>기술스택</strong> Java 17, Spring Batch 5, Spring Boot 3, Oracle 19c, PostgreSQL,
            Metabase, Telegram Bot API, Caffeine Cache</p>

          <section class="career-highlight-list" aria-label="핵심 성과">
            <h4>핵심 성과</h4>

            <div class="career-highlight-grid">
              <article class="career-highlight">
                <h5>대용량 거래를 실시간 분할 처리</h5>
                <p>
                  하루 1회 일괄 처리되던 프로시저를 10분 주기, 1만 건 이하 단위로 분할해 Chunk 기반으로 병렬 실행했습니다.
                  3일치 데이터까지 자동 적재하는 증분 로직을 도입해 재처리 없이 장애를 복구할 수 있게 되었고,
                  병목 구간이 사라져 전체 거래 처리 속도가 40% 빨라졌습니다.
                </p>
              </article>

              <article class="career-highlight">
                <h5>원천사 검증을 자동화하고 속도를 단축</h5>
                <p>
                  원천사별 거래 누락·중복을 자동 점검하는 Batch 단계를 새로 설계하고, 사전 필터링과 No-offset 페이징을 적용했습니다.
                  Clustered Index와 Telegram 알림을 결합해 전체 스캔을 줄이고 결과를 실시간 공유한 덕분에
                  집계 시간이 170초에서 4초로 줄었고 신규 원천사를 설정만으로 확장할 수 있게 됐습니다.
                </p>
              </article>

              <article class="career-highlight">
                <h5>정합성 검증과 자동 보정을 표준화</h5>
                <p>
                  중복·결손 데이터가 감지되면 즉시 예외를 태깅하고 보정 Job이 후속 실행되도록 파이프라인을 재설계했습니다.
                  로그 기반 재시도 로직과 실시간 알림으로 운영자 개입 없이 복구되며,
                  재처리율 0%를 유지하는 정합성 템플릿을 이후 배치 설계의 기준으로 삼았습니다.
                </p>
              </article>

              <article class="career-highlight">
                <h5>월말 마감 병목을 병렬 처리로 해소</h5>
                <p>
                  마감 처리 단계에 Chunk 단위 병렬화를 적용하고 상태 업데이트를 자동화해 지급 시스템과의 연계를 단순화했습니다.
                  마감 집계 속도가 30% 향상되었고, 전체 스케줄 완료 시간이 평균 2시간 이상 단축됐습니다.
                </p>
              </article>

              <article class="career-highlight">
                <h5>가맹점 정산파일 전송을 API로 자동화</h5>
                <p>
                  수작업으로 생성·전송하던 정산파일을 RESTful API 기반 파이프라인으로 재편하고, 파일 생성·전송·검증·백업을 하나의 Job으로 묶었습니다.
                  Caffeine Cache로 반복 쿼리 부하를 줄이고 별도 검증 Job으로 이력을 추적한 결과,
                  전송 누락률 0%와 운영자 일일 1시간 절감을 동시에 달성했습니다.
                </p>
              </article>

              <article class="career-highlight">
                <h5>멀티모듈과 테스트 환경을 정비</h5>
                <p>
                  Core·Domain·Batch 모듈로 분리해 의존성을 정리하고 빌드 시간을 25% 줄였습니다.
                  H2와 PostgreSQL 테스트 환경을 분리하고 EntityFixtureGenerator와 JobParameter Proxy Bean으로 테스트 데이터를 자동 생성해
                  신규 인력 온보딩 기간을 1주에서 3일로 단축했습니다.
                </p>
              </article>

              <article class="career-highlight">
                <h5>모니터링과 로깅을 일상화</h5>
                <p>
                  Telegram 알림으로 Job·Step 상태를 실시간 전파하고 Custom Exception 코드로 오류 유형을 통합했습니다.
                  Metabase 대시보드에 70여 개 검증 쿼리를 시각화해 일일 점검 시간을 1시간에서 5분 이내로 줄였으며,
                  알림 기반 대응 시간도 하루에서 10분 내외로 단축했습니다.
                </p>
              </article>
            </div>
          </section>
        </article>

        <article class="career-block">
          <h3>자동 검증·리포트 파이프라인 / 백엔드 개발자 @ 다날</h3>
          <p>
            기존에는 검증 보고서와 정합성 점검이 수동으로 이루어져, 이상 탐지와 대응이 지연되는 문제가 있었습니다.
            Spring Batch Step Listener와 룰 엔진을 결합하여 거래 상태별 검증 리포트를 자동으로 생성하고 PDF 및 Slack 템플릿으로 배포하는 시스템을 구축했습니다.
            또한 Metabase를 통해 처리량, 오류율, 재시도, 정합성 지표를 실시간으로 시각화하고 SLA 위반 시 조건부 서식을 적용하여 가시성을 높였습니다.
            Telegram Bot API를 활용해 Job과 Step 이벤트, 임계값 초과, 재시도 결과를 실시간으로 알림으로 전송했고,
            재처리·승인·배포 과정을 표준 운영 문서로 정리해 담당자 변경 시에도 1시간 이내에 온보딩이 가능하도록 체계를 마련했습니다.
            이로써 반복 검증 시간이 3시간에서 12분으로 단축되고, 이상 탐지부터 대응까지 평균 5분 이내로 수행할 수 있게 되었습니다.
          </p>
          <p class="career-stack"><strong>기술스택</strong> Spring Batch, Java 17, Metabase, Telegram Bot API, Jenkins,
            GitHub Actions, Slack API</p>
        </article>

        <article class="career-block">
          <h3>마이데이터 백엔드 플랫폼 / 백엔드 개발자 @ 쿠콘</h3>
          <p>
            마이데이터제공자의 입장에서 정보제공자의 업권별 데이터 포맷과 API 규격이 다르고, 각 회사에서 이해하는 데이터의 의미가 상이하여 품질 검증 과정이 병목 구간으로 작용했습니다.
            이를 해결하기 위해 은행·통신·보험·캐피탈 4개 업권의 수집 모듈을 전략 패턴으로 재설계하여 공통 DTO, 검증/ 예외 처리를 제공했습니다.
            거래 및 계좌 무결성 검증 로직을 배치 파이프라인으로 구현하고, 오류 유형을 자동 태깅하는 품질 대시보드를 구축했습니다.
            개인정보 보호 강화를 위해 AES-256/SHA-256 암호화와 전용 키 로테이션 스케줄러를 도입하여 보안성을 강화했고,
            배포/장애 대응/고객 VOC를 위한 Runbook을 정리해 DevOps 대응 속도를 표준화했습니다.
            결과적으로 신규 기관 연동 및 안정화 기간이 평균1.5주에서 2시간 내외로 단축되었고, QA 오류 대응 시간을 절반이상 줄일수 있었습니다.
          </p>
          <p class="career-stack"><strong>기술스택</strong> Spring Boot 2.6, Java 8, PostgreSQL, AES-256/SHA-256, JUnit 5,
            GitLab CI, 내부 대시보드</p>
        </article>
      </div>
    </section>

    <section class="career-softskills" aria-labelledby="career-softskills-title">
      <div class="container">
        <h2 id="career-softskills-title">대외활동</h2>
        <p>
          사내 테크니컬 라이팅 모임의 운영진으로 참여하여 리뷰·발행 프로세스를 정립하고 실무 중심의 기술 글을 지속적으로 발행했습니다.
          이를 통해 개발자 간 지식 공유와 문서화 문화를 확산시켰습니다.
        </p>
      </div>
    </section>
  </main>

  <footer class="site-footer">
    <div class="container">
      <p>© 2025 Tina. All rights reserved.</p>
    </div>
  </footer>
</body>

</html>
